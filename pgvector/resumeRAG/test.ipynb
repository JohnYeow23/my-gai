{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in all the libraries and documents needed for the project\n",
    "import os \n",
    "import bs4\n",
    "import markdown\n",
    "import psycopg2\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.document_loaders  import TextLoader\n",
    "from langchain.text_splitter  import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings  import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, UnstructuredPDFLoader, WebBaseLoader, UnstructuredMarkdownLoader, UnstructuredWordDocumentLoader\n",
    "\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the necessary API needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(27649) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Yes, I can receive your message! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 18, 'total_tokens': 33, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None} id='run-c00de63e-53e5-4699-b182-f72739c91f0f-0' usage_metadata={'input_tokens': 18, 'output_tokens': 15, 'total_tokens': 33, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Tracing via Langsmith\n",
    "trace = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "langsmith = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Build a GPT model\n",
    "gpt = ChatOpenAI(\n",
    "    model = \"gpt-4o\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = gpt.invoke(\"Testing the connection are you able to receive my message?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, split and chunk all of our documentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all the documents \n",
    "pdf_filepath = \"media/Jun Yeow's Resume _ 18_08_2024.pdf\"\n",
    "word_filepath = \"media/Jun Yeow's Resume _ 18_08_2024.docx\"\n",
    "url = \"https://johnyeow23.github.io/JunYeow-Website/\"\n",
    "markdown_path = \"media/Jun Yeow's Resume.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Facing issues with my PYPDF folder for some reason...\n",
    "# pdf_loader  = PyPDFLoader(pdf_filepath)\n",
    "pdf_loader  = UnstructuredPDFLoader(pdf_filepath, mode=\"elements\")\n",
    "print(pdf_loader)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "pdf_documents = pdf_loader.load()\n",
    "print(pdf_documents)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "print(pdf_documents[0].page_content)\n",
    "print(len(pdf_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try word document instead\n",
    "# word_loader = Docx2txtLoader(word_filepath, mode=\"elements\")\n",
    "\n",
    "\n",
    "word_loader = UnstructuredWordDocumentLoader(word_filepath, mode=\"elements\")\n",
    "print(word_loader)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "word_doc= word_loader.load()\n",
    "pprint(word_doc)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "print(word_doc[0])\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "print(len(word_doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website information\n",
    "response = requests.get(url)\n",
    "print(response)\n",
    "\n",
    "web_loader = WebBaseLoader(\n",
    "    web_path=(url),\n",
    ")\n",
    "\n",
    "web = web_loader.load()\n",
    "pprint(web)\n",
    "print(len(web))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown information\n",
    "readme_loader = UnstructuredMarkdownLoader(markdown_path, mode=\"elements\")\n",
    "\n",
    "readme_data = readme_loader.load()\n",
    "\n",
    "print(readme_data)\n",
    "print(len(readme_data))\n",
    "print(readme_data[7].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We loaded the documents in now to split them into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=400)\n",
    "\n",
    "pdf = pdf_splitter.split_documents(pdf_documents)\n",
    "\n",
    "print(pdf)\n",
    "\n",
    "for i in range(len(pdf)):\n",
    "    print(pdf[i].page_content)\n",
    "    print(pdf[i].metadata)\n",
    "print(len(pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[0].metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=400)\n",
    "\n",
    "word = word_splitter.split_documents(word_doc)\n",
    "\n",
    "print(word)\n",
    "\n",
    "for i in range(len(word)):\n",
    "    print(word[i].page_content)\n",
    "print(len(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "web_content = web_splitter.split_documents(web)\n",
    "\n",
    "print(web_content)\n",
    "print(len(web_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=400)\n",
    "\n",
    "readme = readme_splitter.split_documents(readme_data)\n",
    "\n",
    "print(readme)\n",
    "print(len(readme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a combined list instead\n",
    "combined = word + web_content + readme + pdf\n",
    "print(type(combined))\n",
    "print(len(combined))\n",
    "print(combined[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's embed this resume first before adding other informationn into the mix, like\n",
    "    1. My personal website\n",
    "    2. My readme.md\n",
    "    3. Maybe a short description about myself documentation\n",
    "    4. Recommendation letter from past employment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_string = os.getenv(\"CONNECTION_STRING\")\n",
    "\n",
    "collect_word = os.getenv(\"COLLECTION_NAME_WORD\")\n",
    "collect_readme = os.getenv(\"COLLECTION_NAME_README\")\n",
    "collect_web = os.getenv(\"COLLECTION_NAME_WEB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[0].metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straight forward approach\n",
    "vectorstore=PGVector(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=collect_word,\n",
    "    connection_string=connect_string,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "vectors = vectorstore.add_documents(combined, ids=[doc.metadata[\"source\"] for doc in combined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update metadata in the database\n",
    "# for doc in combined:\n",
    "#     last_modified = doc.metadata.get(\"last_modified\")\n",
    "#     links = doc.metadata.get(\"links\")\n",
    "#     if last_modified or links:\n",
    "#         # Assuming you have a method to update metadata in your PGVector class\n",
    "#         vectorstore.collection_metadata(doc, last_modified=last_modified, links=links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create information for each of the different datasource\n",
    "# vectorstore_word=PGVector(\n",
    "#     embedding_function=embeddings,\n",
    "#     collection_name=collect_word,\n",
    "#     connection_string=connect_string,\n",
    "#     use_jsonb=True,\n",
    "# )\n",
    "\n",
    "# vectorstore_word.add_documents(word)\n",
    "\n",
    "# vectorstore_readme=PGVector(\n",
    "#     embedding_function=embeddings,\n",
    "#     collection_name=collect_readme,\n",
    "#     connection_string=connect_string,\n",
    "#     use_jsonb=True,\n",
    "# )\n",
    "\n",
    "# vectorstore_word.add_documents(readme)\n",
    "\n",
    "# vectorstore_web=PGVector(\n",
    "#     embedding_function=embeddings,\n",
    "#     collection_name=collect_web,\n",
    "#     connection_string=connect_string,\n",
    "#     use_jsonb=True,\n",
    "# )\n",
    "\n",
    "# vectorstore_word.add_documents(web_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's checkout if the rows exist within our SQL table.\n",
    "### Before using similarity search to find relevant information to our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the db \n",
    "query = \"Did Jun Yeow work in Grab?\"\n",
    "\n",
    "similar = vectorstore.similarity_search_with_score(query, k=5)\n",
    "\n",
    "for doc in similar:\n",
    "    print('-------------')\n",
    "    print(doc[0].page_content)\n",
    "    print('-------------')\n",
    "    print(doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an AI assistant designed to answer questions from hiring managers and recruiters \"\n",
    "    \"regarding Jun Yeow's professional background, skills, and experiences. Utilize the provided \"\n",
    "    \"context to deliver accurate and concise responses. If the information is not available in the \"\n",
    "    \"context, respond with 'I'm sorry, but I don't have that information.' \"\n",
    "    \"maximum of three sentences.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', system_prompt),\n",
    "        ('human', \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(gpt, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.batch(\n",
    "    [\n",
    "        {\"input\": \"Hey tell me a little about Jun Yeow\"}, \n",
    "        {\"input\": \"Can you tell me more about Jun Yeow's work in Grab?\"},\n",
    "        {\"input\": \"Can I have Jun Yeow's Linkedin?\"},\n",
    "        {\"input\": \"What kind of skills does Jun Yeow have?\"},\n",
    "        {\"input\": \"Can you tell me Jun Yeow's contribution to DAC\"},\n",
    "        {\"input\": \"What makes him good as a Data scientist?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "for answer in response:\n",
    "    print(answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wah shaggy as we can see the rag system isn't really good at replying our answer other then basic questions let's tune it and evaluate the model better.\n",
    "\n",
    "#### There are many ways to approach this \n",
    "    1) Better quality data more descriptive and well documented information instead of bits and pieces of information from everywhere\n",
    "    2) Evaluating/Fine tuning RAG system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out the newly formatted information instead\n",
    "new_loader = Docx2txtLoader(\"media/Jun_Yeow_Organized_Profile.docx\")\n",
    "\n",
    "new_data = new_loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "data = splitter.split_documents(new_data)\n",
    "print(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = os.getenv(\"NEW_CONNECTION_STRING\")\n",
    "name = os.getenv(\"NEW_COLLECTION_NAME\")\n",
    "\n",
    "new_vectorstore=PGVector(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=name,\n",
    "    connection_string=string,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "# vectors = new_vectorstore.add_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_retriever = new_vectorstore.as_retriever()\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an AI assistant designed to answer questions from hiring managers and recruiters \"\n",
    "    \"regarding Jun Yeow's professional background, skills, and experiences. Utilize the provided \"\n",
    "    \"context to deliver accurate and concise responses. If the information is not available in the \"\n",
    "    \"context, respond with 'I'm sorry, but I don't have that information.' \"\n",
    "    \"maximum of three sentences.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', system_prompt),\n",
    "        ('human', \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(gpt, prompt)\n",
    "rag_chain = create_retrieval_chain(test_retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.batch(\n",
    "    [\n",
    "        {\"input\": \"Hey tell me a little about Jun Yeow\"}, \n",
    "        {\"input\": \"Can you tell me more about Jun Yeow's work in Grab?\"},\n",
    "        {\"input\": \"Can I have Jun Yeow's Linkedin?\"},\n",
    "        {\"input\": \"What kind of skills does Jun Yeow have?\"},\n",
    "        {\"input\": \"Can you tell me Jun Yeow's contribution to DAC\"},\n",
    "        {\"input\": \"What makes him good as a Data scientist?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "for answer in response:\n",
    "    print(answer[\"answer\"])\n",
    "\n",
    "# Does seem to have an improvement to the entire quality of answers when we use better data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "from langchain_community.document_loaders import (\n",
    "    UnstructuredMarkdownLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    "    UnstructuredPDFLoader,\n",
    "    WebBaseLoader\n",
    ")\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "pdf_filepath = \"media/Jun Yeow's Resume _ 18_08_2024.pdf\"\n",
    "word_filepath = \"media/Jun Yeow's Resume _ 18_08_2024.docx\"\n",
    "url = \"https://johnyeow23.github.io/JunYeow-Website/\"\n",
    "markdown_path = \"media/Jun Yeow's Resume.md\"\n",
    "docx_path = \"media/Jun_Yeow_Organized_Profile.docx\"\n",
    "\n",
    "def load_and_split_document(source, source_type, chunk_size=2000, chunk_overlap=200):\n",
    "    if source_type == 'markdown':\n",
    "        loader = UnstructuredMarkdownLoader(source, mode=\"elements\")\n",
    "    elif source_type == 'word':\n",
    "        loader = UnstructuredWordDocumentLoader(source, mode=\"elements\")\n",
    "    elif source_type == 'pdf':\n",
    "        loader = UnstructuredPDFLoader(source, mode=\"elements\")\n",
    "    elif source_type == 'url':\n",
    "        loader = WebBaseLoader(web_path=source)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported source_type: {source_type}\")\n",
    "\n",
    "    documents = loader.load()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    split_documents = splitter.split_documents(documents)\n",
    "    return split_documents\n",
    "\n",
    "pdf_docs = load_and_split_document(pdf_filepath, 'pdf')\n",
    "word_docs = load_and_split_document(word_filepath, 'word')\n",
    "url_docs = load_and_split_document(url, 'url')\n",
    "markdown_docs = load_and_split_document(markdown_path, 'markdown')\n",
    "docx_docs = load_and_split_document(docx_path, 'word')\n",
    "\n",
    "combined = pdf_docs + word_docs + url_docs + markdown_docs + docx_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://johnyeow23.github.io/JunYeow-Website/', 'title': \"Jun Yeow's Portfolio\", 'language': 'No language found.'}\n"
     ]
    }
   ],
   "source": [
    "print(url_docs[0].metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database storing the embeddings\n",
    "db=PGVector(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=collect_word,\n",
    "    connection_string=connect_string,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "db.add_documents(combined, ids=[chunk.metadata[\"source\"] for chunk in combined])\n",
    "\n",
    "test_retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an AI assistant designed to answer questions from hiring managers and recruiters \"\n",
    "    \"regarding Jun Yeow's professional background, skills, and experiences. Utilize the provided \"\n",
    "    \"context to deliver accurate and concise responses. If the information is not available in the \"\n",
    "    \"context, respond with 'I'm sorry, but I don't have that information.' \"\n",
    "    \"maximum of three sentences.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', system_prompt),\n",
    "        ('human', \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(gpt, prompt)\n",
    "rag_chain = create_retrieval_chain(test_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    chat_history: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    context: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: State):\n",
    "    response = rag_chain.invoke(state)\n",
    "    return {\n",
    "        \"chat_history\":[\n",
    "            HumanMessage(state[\"input\"]),\n",
    "            AIMessage(response[\"answer\"]),\n",
    "        ],\n",
    "        \"context\": response[\"context\"],\n",
    "        \"answer\": response[\"answer\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = Stategraph(state_schema=State)\n",
    "workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch pad\n",
    "    1) Evaluation using langsmith? Not too sure of the evaluation methods need to research.\n",
    "    2) Build out the entire system.\n",
    "    3) One more for the question and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the database to fit our needs a little better\n",
    "\n",
    "# Connect to PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"johnresume_db\",\n",
    "    user=os.getenv(\"POSTGRES_USER\"),\n",
    "    password=os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    host=\"localhost\",  # Or your host address\n",
    "    port=\"5432\"        # Default PostgreSQL port\n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns if they don't already exist\n",
    "try:\n",
    "    # cursor.execute(\"ALTER TABLE langchain_pg_embedding ADD COLUMN IF NOT EXISTS index INTEGER;\")\n",
    "    cursor.execute(\"ALTER TABLE langchain_pg_embedding ADD COLUMN IF NOT EXISTS created_datetime TIMESTAMP;\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding columns: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Insert data into the table\n",
    "for index in range(len(word)):\n",
    "    try:\n",
    "        cursor.execute(\n",
    "            # \"INSERT INTO langchain_pg_embedding (index, created_datetime) VALUES (%s, %s)\",\n",
    "            \"INSERT INTO langchain_pg_embedding (created_datetime) VALUES (%s)\",\n",
    "            # (index, current_time)\n",
    "            (current_time)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit and close connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-learning-3IM81iVc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
