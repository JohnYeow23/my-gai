{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in all the libraries and documents needed for the project\n",
    "import os \n",
    "import bs4\n",
    "import markdown\n",
    "import psycopg2\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.document_loaders  import TextLoader\n",
    "from langchain.text_splitter  import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings  import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the necessary API needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracing \n",
    "trace = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "langsmith = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = ChatOpenAI(\n",
    "    model = \"gpt-4o\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.invoke(\"Testing the connection are you able to receive my message?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, split and chunk all of our documentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_filepath = \"media/Jun Yeow's Resume _ 18_08_2024.pdf\"\n",
    "word_filepath = \"media/Jun Yeow's Resume _ 18_08_2024.docx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Facing issues with my PYPDF folder for some reason...\n",
    "pdf_loader  = PyPDFLoader(pdf_filepath)\n",
    "print(pdf_loader)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "pdf_documents = pdf_loader.load()\n",
    "print(pdf_documents)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "print(pdf_documents[0].page_content)\n",
    "print(len(pdf_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try word document instead\n",
    "word_loader = Docx2txtLoader(word_filepath)\n",
    "print(word_loader)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "word_doc= word_loader.load()\n",
    "pprint(word_doc)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "print(word_doc[0])\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "print(len(word_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website information\n",
    "url = \"https://johnyeow23.github.io/JunYeow-Website/\"\n",
    "response = requests.get(url)\n",
    "print(response)\n",
    "\n",
    "web_loader = WebBaseLoader(\n",
    "    web_path=(url),\n",
    ")\n",
    "\n",
    "web = web_loader.load()\n",
    "pprint.pprint(web)\n",
    "print(len(web))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown information\n",
    "markdown_path = \"media/Jun Yeow's Resume.md\"\n",
    "\n",
    "readme_loader = UnstructuredMarkdownLoader(markdown_path, mode=\"elements\")\n",
    "\n",
    "readme_data = readme_loader.load()\n",
    "\n",
    "print(readme_data)\n",
    "print(len(readme_data))\n",
    "print(readme_data[7].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We loaded the documents in now to split them into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=100)\n",
    "\n",
    "word = word_splitter.split_documents(word_doc)\n",
    "\n",
    "print(word)\n",
    "\n",
    "for i in range(len(word)):\n",
    "    print(word[i].page_content)\n",
    "print(len(word)) # 4 Chunks Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=100)\n",
    "\n",
    "web_content = web_splitter.split_documents(web)\n",
    "\n",
    "print(web_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=100)\n",
    "\n",
    "readme = readme_splitter.split_documents(readme_data)\n",
    "\n",
    "print(readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a combined list instead\n",
    "combined = word + web_content + readme\n",
    "print(type(combined))\n",
    "print(len(combined))\n",
    "print(combined[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's embed this resume first before adding other informationn into the mix, like\n",
    "    1. My personal website\n",
    "    2. My readme.md\n",
    "    3. Maybe a short description about myself documentation\n",
    "    4. Recommendation letter from past employment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_string = os.getenv(\"CONNECTION_STRING\")\n",
    "collect_word = os.getenv(\"COLLECTION_NAME_WORD\")\n",
    "collect_readme = os.getenv(\"COLLECTION_NAME_README\")\n",
    "collect_web = os.getenv(\"COLLECTION_NAME_WEB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straight forward approach\n",
    "vectorstore=PGVector(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=collect_word,\n",
    "    connection_string=connect_string,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "vectors = vectorstore.add_documents(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create information for each of the different datasource\n",
    "# vectorstore_word=PGVector(\n",
    "#     embedding_function=embeddings,\n",
    "#     collection_name=collect_word,\n",
    "#     connection_string=connect_string,\n",
    "#     use_jsonb=True,\n",
    "# )\n",
    "\n",
    "# vectorstore_word.add_documents(word)\n",
    "\n",
    "# vectorstore_readme=PGVector(\n",
    "#     embedding_function=embeddings,\n",
    "#     collection_name=collect_readme,\n",
    "#     connection_string=connect_string,\n",
    "#     use_jsonb=True,\n",
    "# )\n",
    "\n",
    "# vectorstore_word.add_documents(readme)\n",
    "\n",
    "# vectorstore_web=PGVector(\n",
    "#     embedding_function=embeddings,\n",
    "#     collection_name=collect_web,\n",
    "#     connection_string=connect_string,\n",
    "#     use_jsonb=True,\n",
    "# )\n",
    "\n",
    "# vectorstore_word.add_documents(web_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's checkout if the rows exist within our SQL table.\n",
    "### Before using similarity search to find relevant information to our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the db \n",
    "query = \"Did Jun Yeow work in Grab?\"\n",
    "\n",
    "similar = vectorstore.similarity_search_with_score(query, k=5)\n",
    "\n",
    "for doc in similar:\n",
    "    print('-------------')\n",
    "    print(doc[0].page_content)\n",
    "    print('-------------')\n",
    "    print(doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an AI assistant designed to answer questions from hiring managers and recruiters \"\n",
    "    \"regarding Jun Yeow's professional background, skills, and experiences. Utilize the provided \"\n",
    "    \"context to deliver accurate and concise responses. If the information is not available in the \"\n",
    "    \"context, respond with 'I'm sorry, but I don't have that information.' \"\n",
    "    \"maximum of three sentences.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', system_prompt),\n",
    "        ('human', \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(gpt, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jun Yeow is a Data Science student at the University of London with a strong passion for Machine Learning. He is pursuing a Bachelor of Science (Honours) in Data Science and Business Analytics and is currently in his penultimate year.\n",
      "Jun Yeow worked as a People Data Analytics Intern at Grab from January 2024 to August 2024, focusing on Human Resource Analytics. During this internship, he worked on projects aimed at improving the employee experience.\n",
      "I'm sorry, but I don't have that information.\n",
      "I'm sorry, but I don't have that information.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.batch(\n",
    "    [\n",
    "        {\"input\": \"Hey tell me a little about Jun Yeow\"}, \n",
    "        {\"input\": \"Can you tell me more about Jun Yeow's work in Grab?\"},\n",
    "        {\"input\": \"Can I have Jun Yeow's Linkedin?\"},\n",
    "        {\"input\": \"What kind of skills does Jun Yeow have?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "for answer in response:\n",
    "    print(answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wah shaggy as we can see the rag system isn't really good at replying our answer other then basic questions let's tune it and evaluate the model better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the database to fit our needs a little better\n",
    "\n",
    "# Connect to PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"johnresume_db\",\n",
    "    user=os.getenv(\"POSTGRES_USER\"),\n",
    "    password=os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "    host=\"localhost\",  # Or your host address\n",
    "    port=\"5432\"        # Default PostgreSQL port\n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns if they don't already exist\n",
    "try:\n",
    "    # cursor.execute(\"ALTER TABLE langchain_pg_embedding ADD COLUMN IF NOT EXISTS index INTEGER;\")\n",
    "    cursor.execute(\"ALTER TABLE langchain_pg_embedding ADD COLUMN IF NOT EXISTS created_datetime TIMESTAMP;\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding columns: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Insert data into the table\n",
    "for index in range(len(word)):\n",
    "    try:\n",
    "        cursor.execute(\n",
    "            # \"INSERT INTO langchain_pg_embedding (index, created_datetime) VALUES (%s, %s)\",\n",
    "            \"INSERT INTO langchain_pg_embedding (created_datetime) VALUES (%s)\",\n",
    "            # (index, current_time)\n",
    "            (current_time)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit and close connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector database to store all our items within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-learning-3IM81iVc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
